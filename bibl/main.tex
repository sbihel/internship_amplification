\documentclass[11pt]{sdm}

\usepackage{graphicx}
\graphicspath{{../img/}}

\usepackage{subcaption}
\usepackage{cleveref}

\pagestyle{plain}

\usepackage{hyperref}
\usepackage{url} \urlstyle{sf}
\newcommand{\email}[1]{\href{mailto:#1}{#1}}

\usepackage{xspace}

\usepackage[dvipsnames]{xcolor}
\newcommand{\addref}[1]{\colorbox{TealBlue!100}{\textcolor{white}{\textbf{$[$\ifx&#1&\ \else#1\fi$]$}}}}
\newcommand{\todo}[1]{\colorbox{Red!75}{\textcolor{white}{\textbf{TODO\ifx&#1&\else: #1\fi}}}}
\newcommand{\done}{\colorbox{YellowGreen!100}{\textcolor{white}{\textbf{DONE}}}}
\newcommand{\review}{\colorbox{YellowOrange!100}{\textcolor{white}{\textbf{REVIEW}}}}

\newcommand{\dspot}{DSpot\xspace}
\newcommand{\pitest}{Pitest\xspace}

\usepackage{listings}
\lstset{%
%  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\small,        % the size of the fonts that are used for the code
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{cyan},    % comment style
  escapeinside={(*@}{@*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{red},       % keyword style
  numberstyle=\tiny\color{black}, % the style that is used for the line-numbers
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  title=\lstname,                   % show the filename of files included with \lstinputlisting; also try caption instead of title
  language=Java,
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  %frame=single,                    % adds a frame around the code
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  tabsize=2                       % sets default tabsize to 2 spaces
}

\title{Search-Based Test Amplification}

\author{Simon \textsc{Bihel}}
\supervisorOne{Benoit \textsc{Baudry}}
\supervisorTwo{~}
\team{KTH Royal Institute of Technology}
\school{ens-Rennes}

\domain{Domain: Software Engineering - Artificial Intelligence}

\abstract{%
% With the poor use of formal specifications for software development, programmers ensure the well-behavior of software with hand-written tests.%
% Meta-heuristic optimizing techniques are used to automate the process of testing (e.g.\ generating test data).%
% %
% With practices such as test-driven development, software projects come with strong test suites.%
% Knowledge of the expected properties of the program can be extracted from the large number of test cases.%
% This knowledge can be used in turn to enhance the test suite to improve certain software metrics.%
% %
% Different goals can be pursued to reduce the likelihood of bugs, to help during debugging, etc.%
% The amplification can be achieved by generating variants of existing tests, modifying the tests execution, etc.%
}

\date{February 2018}

% Ought to be 10 to 15 pages long

\begin{document}
\maketitle

\section*{Introduction}
\label{intro}
% ----- Context
Tests embed the knowledge of expected behavior of a software.
With practices such as test-driven development, software projects now come with strong test suites.
While it is essential to hunt for bugs, the cost in time is significant for programmers as they can end up spending a majority of their time on writing test.
As always we want to reduce the human cost by searching for tasks to automate.

% ----- Test Data Generation and SBSE
The problem of automatically generating tests has been around for decades but these techniques have to start from scratch, assuming that no external help is available.
A field that has been tackling these large problems is the Search-Based Software Engineering in which dynamic and approximate techniques are used in order to find solutions in a reasonable time.
With new test practices we can work on extending previous techniques in hope of better performance and smarter tests.

% ----- State of the Art
Different tools have been developed, more or less general in the goal they try to achieve (e.g.\ test more parts, optimize the tests execution).
This internship will focus on one particular tool called~\dspot{}.
It is a tool that creates new test cases with the purpose of finding more bugs.

% ----- Outline
After explaining the basics of Search-Based Software Testing in Section~\ref{sbse} we will present how it can be used to amplify test suites in Section~\ref{tsa}.
In Section~\ref{planned} we detail the different paths the internship could explore.


% ========== Section 1 ==========
\section{Search-Based Software Engineering}
\label{sbse}

In this section we present the reasons for the emergence of Search-Based Software Engineering (SBSE)~\cite{harman2001search,mcminn2011search} and give examples of applications.

\subsection{Motivations}
\label{motiv}
\todo{}

Software projects are continuously getting more complex.
They often rely on informal specifications that change during the evolution of the project.
Because of the scale and weak structure, formal methods cannot be used in many cases.

In order to tackle problems such as optimization or testing, we need insightful approximating methods.

Over time software engineers have developed many metrics to evaluate a piece of software and get feedback on its quality.

\subsection{Search-Based Optimization Algorithms}
\label{example_algo}
\review{}

To reach a software engineering goal for these complex systems we use \textit{soft-computing} (or \textit{computational intelligence}) to find inexact or sub-optimal solutions in a reasonable time.
In Section~\ref{basic_algo} we present some algorithms to give an idea of the capabilities of these techniques.
In Section~\ref{fitness_func} we show how we can pursue engineering goals with these optimization processes.

\subsubsection{Basic algorithms}
\label{basic_algo}

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{hillclimbing}
\caption{Hill Climbing}
\label{fig:hill_climbing}
  \end{subfigure}%
~%
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{simulated_annealing}
\caption{Simulated Annealing}
\label{fig:simulated_annealing}
  \end{subfigure}%
~%
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{genetic_algo}
\caption{Genetic Algorithm}
\label{fig:genetic_algo}
  \end{subfigure}
\caption{Basic optimization algorithms}
\label{fig:optimization_algos}
\end{figure}

% ----- Hill Climbing & Simulated Annealing
The simplest form of such algorithm is the Hill Climbing.
Its process is pictured in \figurename~\ref{fig:hill_climbing}.
It only consists of starting from a random position and from there, and iteratively, find a direction to move in to improve the fitness function.
As the algorithm is searching only for direct improvement we can only find a local optima.
We could start the algorithm with a different starting position but we can also allow the algorithm to move in a direction that does not improve directly the score in the hope to later find a higher local optima.
This is called Simulated Annealing and we show an example in \figurename~\ref{fig:simulated_annealing}.

% ----- Genetic Algorithm
These methods are described as `local' search approaches as they only consider only one solution at a time.
Genetic Algorithms (GAs), on the other hand, consider multiple points in the search space at once as shown in \figurename~\ref{fig:genetic_algo}.
Each point is referred as an `individual' and the set of individuals is called a `population'.
Each iteration we keep the fittest individuals and do crossover of them to generate new individuals.
In a multi-dimensional search space we can see dimensions as genes and a crossover is the combination of genes from two individuals.

% ----- How to use them for real problems?
In order to use these methods for software engineering problems we have two requirements:
\begin{description}
  \item[Representation] We need to encode our individuals, e.g.\ programs, in a way that they can be manipulated by the optimization algorithm. We will explore this problem in Section~\ref{applications}.
  \item[Fitness function] We need a way to tell that an individual is better than another one, e.g.\ that a program is safer than another one. We present the use of software metrics as fitness function next in Section~\ref{fitness_func}.
\end{description}

\subsubsection{Metrics as fitness functions}
\label{fitness_func}
% ----- Motivations for metrics
Evaluating a piece of code automatically is not an easy task depending on the property we want to assess.
To evaluate the performances, one might just run the program with a certain kind of workload.
But when we want to tell the chances of having bugs or tell that the modularity will not get in the way of future evolution, it gets harder.
These properties are already difficult to express informally and often depend on a programmer's intuition that has developed over years of practice.
Because companies need to be able to tell if their products are of good quality, significant efforts from the industry and research worlds have been put in developing \textit{metrics}.

% ----- Metrics for testing
As the internship will focus on testing, we will spend a bit of time here to present metrics used to assess the quality and quantity of testing, and thus the likelihood of absence of bugs.
One that is widely used is the \textit{code coverage} metric.
Informally, it is the amount of code executed by a test suite.
It can be as simple as the percentage of statement executed, or something more complex and thus more likely to find edge cases and bugs.
For example, the branch coverage, where you want every branch of each control structure to be executed.
Many variants exist, each with its bugs category that it can find and its cost as it requires the execution of many tests.

% ----- Mutation score
To add more confidence that the test suite is effective, we can evaluate it by voluntarily introducing bugs in the software and see if it is capable of detecting them.
This is what we call \textit{mutation testing} as we are creating \textit{mutants} of the main piece of software.
In Section~\ref{applications} we explain how to create such mutants.

\subsection{Genetic Improvement}
\label{applications}
\todo{}
% ----- Intro to genetic improvement
SBSE techniques can be applied to modify and improve existing software in what is called \textit{Genetic Improvement} (GI)~\cite{petke2017genetic}.
In order to modify a program we need a representation and \textit{operators} (i.e.\ set of possible actions).
Numerous representations exist such as ASTs, bytecode, the program's text file itself, etc.
Then the operators can range from modifying elementary operators (e.g.\ addition) to deleting unused part of the program.

% ----- Why is it possible?
The range of possible programs is so vast that we need: (i) methods such as evolutionary computing which is well-suited to finding good trade-offs between potentially competing objectives; (ii) use the fact that human-developed code is repetitive; and (iii) not start from scratch and use human knowledge.

% ----- use tests as a guide for semantic faithfulness
In particular, tests can act as a guide for semantic faithfulness and, as we have seen, to assess the degree of improvement.

% \cite{xuan2015dynamic}


% ========== Section 2 ==========
\section{Test Suite Amplification}
\label{tsa}
In this section we present the specific problem of enhancing an existing test suite~\cite{danglot2017emerging}.
First, Section~\ref{motiv_tsa} exposes the motivations for trying to amplify a preexisting and seemingly strong test suite.
Then Section~\ref{related} presents a few papers to give an idea of the related works.
The tool that the internship will be based on is called \dspot{} and it is presented in Section~\ref{testsuite_eval}.

\addref{new survey paper}

\subsection{Motivations}
\label{motiv_tsa}
\todo{}

% ----- Why it is possible
Important projects from big companies now come with extensive test suites thanks to good practices.
It is thus reasonable to try and see if we can push even further the quality of such projects.
To achieve that, we want automated tools that can generate additional tests in order to evaluate more situations, or rework the test suite to have a better score for a certain fitness function (e.g.\ optimizing tests execution time).
In either way we preserve the original, hand-written, test suite as it contains much of the human knowledge of the expected behavior of the software.

% ----- How we can use the test suite
We can see the test suite as a starting population of good quality for our evolutionary algorithms.
But most importantly, we can use the test suite as a set of specifications that give us knowledge about what the software is supposed to do and thus allow us to detect more bugs.
It gives us an \textit{oracle}.

\begin{lstlisting}[caption={An archetypal example of an object-oriented test case  (taken from the Apache Commons Collections, in the class TreeListTest, line 270)},label=lst:archetype,float,language=java,numbers=left]
testIterationOrder() {
  TreeList tl = new TreeList(10); (*@\label{input-begin}@*)
  for (int i = 0; i < size; i++)
    {tl.add(i);}(*@\label{input-end}@*)
  int i = 0;
  ListIterator it = tl.listIterator();(*@\label{test}@*)
  while (it.hasNext()) {
    Integer val = it.next();
    assertEquals(i++, val.intValue());
  }
}
\end{lstlisting}

% ----- What can we do with it
An example of test case is given in Listing~\ref{lst:archetype}.


\subsection{Related Works}
\label{related}
Before presenting the tool that the internship will focus on, we present some related works to give an idea of amplification goals and amplification techniques.
In Section~\ref{brefactoring} we present a tool with the goal of helping fault-localization.
Then two other general purpose test data generators are presented in Sections~\ref{tdr} and~\ref{evosuite}.

\subsubsection{B-Refactoring}
\label{brefactoring}
% ----- Introduction
To give an example of a precise software engineering goal and test suite refactoring, we chose to present B-Refactoring~\cite{xuan2016b}.
It is a test code refactoring technique to split a test case into small test fragments, helping for fault localization for example.

% ----- Precise goal
To explain in more details, the goal is to have a simpler part of the control flow for each test.
Test cases, especially hand-written ones, can test different properties at once but the problem is that certain analysis which use tests traces require simple control flows in order to increase their precision.
An example is the process of bug fixing, in which you need to locate the source of the bug in order to fix it.
A test suite based tool for fault localization would run the test suite and, using the test traces, locate the faulty part that is executed by the failed tests and not by the passing tests.
In the case of an \texttt{if} condition where in the execution of a test where both branches are executed, there is not enough precision for the fault localization tool to be effective.

% ----- How to they do it?
To have a test suite that is better suited for fault localization, B-Refactoring will \textit{split} tests that explore multiple branches into smaller tests --- keeping the same overall behavior.

\todo{explain the technique}

\subsubsection{Test Data Regeneration}
\label{tdr}
% ----- Introduction
An example of work on generating additional test cases from an existing test suite is the work of Search-based Test Data Regeneration (TDR)~\cite{yoo2012test}.
It is a technique that generates new tests in order to improve a given fitness function (e.g.\ branch coverage).

% ----- How do they do it?
\todo{}

\subsubsection{Evosuite}
\label{evosuite}
\cite{fraser2011evosuite}
\todo{}


\subsection{DSpot}
\label{testsuite_eval}
\todo{}
% ----- Introduction


\begin{figure}
  \centering
  \fbox{\includegraphics[trim=2cm 17.02cm 4.09cm 10.46cm, clip]{rq3_resources/protostuff.pdf}}
  \caption{Example of what \dspot{} produces: a diff to improve an existing test case.}
\label{fig:diff-protostuff}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.5]{io-spaces.pdf}
  \caption{On the left, the testing input space is composed by specified input points (orange diamonds) and unspecified input points (black diamonds). On the right, the observation space over a given program state depicts the assertions of tests. The green circles are values that are already asserted in the existing test suite, the newly added assertions are shown as black circles.}
\label{fig:io-spaces}
\end{figure}

\cite{pawlak2016spoon}
\addref{new dspot paper}
\cite{baudry2015dspot} %,baudry2015automatic,baudry2014tailored


% ========== Section 3 ==========
\section{Planned Work}
\label{planned}
This section explains the different paths that we could explore during the internship.

\subsection{Evaluation of the Added Value of Hand-Written Tests}
\label{evaluation}
\todo{}
% ----- Motivations
Up to now, no empirical evaluation has been done on the added value of amplification rather than generating tests from scratch.
Even if it seems obvious that it helps, with insights on the semantics and a strong starting population for evolutionary algorithms, it is important to experimentally measure the gain.

% ----- Methodology
\todo{what kind of experiments}

\subsection{Using Literals Found in Source Code}
\label{mutation}
% ----- Problem statement
Among elementary types are character strings.
With a problem such as test data generation, it is often difficult to generate valid strings as the search space is large and specific values are expected.
But in such cases where there are explicit equality tests, one could collect these precise values and limit the search space to them.

% ----- How could we do it?
We have different options to achieve this collection.
A purely dynamic of doing things would be to instrument the code to detect when the argument is used in an equality test and from there collect a value that would be accepted.
Another possibility would be to statically harvest all literals found in the code.
% TODO advantages?

% ----- How would we evaluate it?
As an evaluation, a comparison with and without this enhancement on programs that heavily rely on string would be sufficient.

\subsection{Creating mutation operators for specific data structures}
\label{create_operators}
\todo{}
% ----- Problem statement
In the same branch of the strings generation problem, with complex and multi-dimensional data structures that often need precise comfiguration, we need smarter generator and mutation operators to avoid senseless inputs.

\subsection{Stacking mutations}
\label{stacking}
\todo{}
% ----- Problem statement
For now in~\dspot{}, when a program is modified, a single mutation operator is applied.
It makes it easy to detect precise weaknesses in the System Under Test by at the same time we could detect more weaknesses by stacking mutations.
Evolved tests would be more complex and more distant from the existing test suite.

% ----- Contribution
Of course there would be smaller chances of generate good inputs but we could study the interactions between various mutation operators to only use the ones that would work well together.

\subsection{Adding Explanations}
\label{explanation}
% ----- Problem statement
When a new test is generated and found useful, a merge/pull request is created for the developer to decide whether to accept the new test.
The role of the developer is to judge the usefulness of the additional test.
% TODO why actually?
As always we want to minimize to efforts from the human so we need to help the developer by explaining the new test.
It is also essential to explain why a test is relevant because in most cases a test that is not understood will be at best ignored, at worst labeled as false positive~\cite{bessey2010few}.

A similar problem is the ordering of pull requests.
If we could in some way define the importance of tests we could present to the developer the most important tests first.

% ----- How would we do it?
\todo{how would we do it?}

\subsection{Learning the set of good amplification operators}
\label{learning}
\todo{}
% ----- Problem statement
In order to generate the least amount of programs that don't make sense, knowing which operators work well in general would make them used more often.

\subsection{Reduce the amplified tests to a minimal set of useful tests}
\label{minimal}
% ----- Problem statement
Overall, the ultimate goal would be to generate a minimal set of amplified tests.

% ----- How would we do it?
In order to achieve this, we could explore different options.
With a post treatment we would, from a complete set of tests, we could remove overlapping tests, fusion others, split tests depending on the different goals achieved, etc.
On the other hand, to avoid tests that would end up being removed or modified we could generating from the start with a more detailed goal.
In this way would could also replace another test if needed.


\section*{Conclusion}
\label{conclu}
\todo{recall what will be done, in what context}


\bibliographystyle{ieeetr}
\bibliography{bibl}

\end{document}
