# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+TITLE: Internship with Benoit Baudry at KTH
#+DATE: <2018-02-07 Wed>--<2018-06-22 Fri>
#+AUTHOR: Simon Bihel
#+EMAIL: [[mailto:simon.bihel@ens-rennes.fr]]
#+WEBSITE: [[simonbihel.me]]
#+LINK: [[https://github.com/sbihel/internship_amplification]]
#+LANGUAGE: en


* Introduction


* Findings
** Bibliography
*** Writing

*** References
**** Cultural
- /Search Based Software Engineering: Techniques, Taxonomy, Tutorial/
  ([[https://www.researchgate.net/profile/Mark_Harman/publication/221051156_Search_Based_Software_Engineering_Techniques_Taxonomy_Tutorial/links/0046352052592d5c2c000000/Search-Based-Software-Engineering-Techniques-Taxonomy-Tutorial.pdf][harman2012search]])
  + TODO
- /A Few Billion Lines of Code Later/
  ([[https://pdfs.semanticscholar.org/295f/4ffa651675b22ae8e2f3f30b400330da0c69.pdf][bessey2010few]])
  + Great to understand the limits of static analysis but also some of the
    limits of all analysis
  + Difficult to analyze code because of the diversity of build automation tools
  + "By default, companies refuse to let an external force modify anything."
  + "A misunderstood explanation means the error is ignored or, worse,
    transmuted into a false positive."
  + Many standards
  + Some people don't care about bugs, sometimes improving the tool reveals more
    bugs which is bad for the manager
- /Spoon: A Library for Implementing Analyses and Transformations of Java Source Code/
  ([[https://hal.archives-ouvertes.fr/hal-01078532v2/document][pawlak2016spoon]])
  + let's say it's like llvm/clang for now
- /Regression Testing Minimisation, Selection and Prioritisation : A Survey/
  ([[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.169.8696&rep=rep1&type=pdf][yoo2012regression]])
  + TODO
- /Clustering Test Cases to Achieve Effective & Scalable Prioritisation Incorporating Expert Knowledge/
  ([[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.211.9479&rep=rep1&type=pdf][yoo2009clustering]])
  + TODO
- /Measuring software redundancy/
  ([[https://pdfs.semanticscholar.org/0a93/144638ebfc924550798b620835a3fc9785cf.pdf][carzaniga2015measuring]])
  + TODO
- /Automatic Software Diversity in the Light of Test Suites/
  ([[https://arxiv.org/pdf/1509.00144.pdf][baudry2015automatic]])
  + analysis of common features (e.g. number of tests covering one statement)
  + plastic behavior (have different behaviors while still remaining correct)
    study
  + different details compared to [[baudry2015dspot]] and [[baudry2014tailored]]
- /Tailored source code transformations to synthesize computationally diverse program variants/
  ([[https://arxiv.org/pdf/1401.7635][baudry2014tailored]])
  + More details than in [[baudry2015dspot]]

**** Search-based Software Testing
- /Search-based software testing: Past, present and future/
  ([[http://mcminn.io/publications/c18.pdf][mcminn2011search]])
  + Already read from previous internship
- /Genetic Improvement of Software: a Comprehensive Survey/
  ([[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7911210][petke2017genetic]])
  + TODO
  + [[http://www.cs.bham.ac.uk/~wbl/biblio/][http://www.cs.bham.ac.uk/~wbl/biblio/]]
- /Evosuite/
  ([[http://www.evosuite.org/evosuite/][fraser2011evosuite]])
  + State-of-the-art tool
  + Very sophisticated, difficult to reproduce experiments because it changes
    fast and a lot of parameters are tweaked

**** Test Amplification
- /B-Refactoring: Automatic Test Code Refactoring to Improve Dynamic Analysis/
  ([[https://hal.archives-ouvertes.fr/hal-01309004/file/banana-refactoring.pdf][xuan2016b]])
  + Split tests for each fragment to cover a simple part of the control flow.
  + Help with respect to fault localization.
- /Test data regeneration: generating new test data from existing test data/
  ([[http://www0.cs.ucl.ac.uk/staff/mharman/stvr-regeneration.pdf][yoo2012test]])
  + TODO
- /The Emerging Field of Test Amplification: A Survey/
  ([[https://arxiv.org/pdf/1705.10692.pdf][danglot2017emerging]])
  + Dense
  + Good overview of goals (Table 1) and methods (Table 2)
- /DSpot: Test Amplification for Automatic Assessment of Computational Diversity/
  ([[https://arxiv.org/pdf/1503.05807.pdf][baudry2015dspot]])
  + Comparison with TDR [[yoo2012test]] and also concurrent to
    [[carzaniga2015measuring]]
    - "the key differences between DSpot and TDR are: TDR stacks multiple
      transformations together; DSpot has more new transformation operators on
      test cases: DSpot considers a richer observation space based on arbitrary
      data types and sequences of method calls."
    - "We count the number of variants that are identified as computationally
      different using DSpot and TDR. "
- /A Systematic Literature Review on Test Amplification/
  + TODO
- /Genetic-Improvement based Unit Test Amplification for Java/
  + TODO
- /Dynamic Analysis can be Improved with Automatic Test Suite Refactoring/
  ([[https://arxiv.org/pdf/1506.01883.pdf][xuan2015dynamic]])
  + TODO
- /Automatic Test Case Optimization: A Bacteriologic Algorithm/
  ([[https://www.researchgate.net/profile/Jean-Marc_Jezequel/publication/3248230_Automatic_Test_Case_Optimization_A_Bacteriologic_Algorithm/links/0912f50ca4c15eb416000000.pdf][baudry2005automatic]])
  + TODO
  + Compared to DSpot, no assertions generation, small programs.

**** Generating natural language descriptions for software artifacts
- /On Automatically Generating Commit Messages via Summarization of Source Code Changes/
  ([[https://www.researchgate.net/profile/Luis_Cortes11/publication/267326224_On_Automatically_Generating_Commit_Messages_via_Summarization_of_Source_Code_Changes/links/5583f12208ae4738295bd3ca.pdf][cortes2014automatically]])
  /ChangeScribe: A Tool for Automatically Generating Commit Messages/
  ([[http://www.cs.wm.edu/~denys/pubs/ICSE%2715-ChangeScribeTool-CRC.pdf][linares2015changescribe]])
  + TODO
  + Good entry point for the related work
  + Classifies commit with stereotypes
  + Uses templates for sentences, and fills it with commit stereotypes
    ([[dragan2011using]])
- /Comment Generation for Source Code: State of the Art, Challenges and Opportunities/
  ([[https://arxiv.org/pdf/1802.02971.pdf]])
  + TODO
  + Information Retrieval ("analyze the natural language clues in the source
    code") -> not relevant
  + Program Structure Information (summary from important statements) -> not
    relevant(?)
  + Software Artifacts Beyond Source Code (using the social interaction
    revolving around development) -> not relevant
  + Fundamental NLP Techniques -> not relevant
  + Not very useful... "current approach only generate descriptive comments"
- /Using Stereotypes to Help Characterize Commits/
  ([[http://www.cs.kent.edu/~jmaletic/papers/ICSM11.pdf][dragan2011using]])
  + Only categorize based on added or deleted methods
- /Summarizing Software Artifacts: A Literature Review/
  ([[https://link.springer.com/content/pdf/10.1007%2Fs11390-016-1671-1.pdf][nazar2016summarizing]])
  + TODO
- /The Emergent Laws of Method and Class Stereotypes in Object Oriented Software/
  ([[https://etd.ohiolink.edu/!etd.send_file?accession=kent1290570321&disposition=inline][dragan2011emergent]])
  + Excerpt from PhD Thesis
  + Source of the Taxonomy of Method Stereotypes
- /Automatically Documenting Software Artifacts/
  ([[http://www.cs.wm.edu/~denys/pubs/dissertations/Boyang-thesis.pdf][li2018automatically]])
  + TODO
  + PhD thesis
  + Chapter 4 on tag for unit tests
- /Survey of Methods to Generate Natural Language from Source Code/
  ([[http://www.languageandcode.org/nlse2015/neubig15nlse-survey.pdf][neubig2016survey]])
  + TODO
- /Towards Automatic Generation of Short Summaries of Commits/
  ([[https://arxiv.org/pdf/1703.09603.pdf][jiang2017towards]])
- /Automatically Generating Commit Messages from Diffs using Neural Machine Translation/
  ([[https://arxiv.org/pdf/1708.09492.pdf][jiang2017automatically]])
  + trying to be less verbose and add context

**** Commits/Code survey
- /What’s a Typical Commit? A Characterization of Open Source Software Repositories/
  ([[https://www.researchgate.net/profile/Huzefa_Kagdi/publication/4349695_What%27s_a_Typical_Commit_A_Characterization_of_Open_Source_Software_Repositories/links/00b7d528a6e2589336000000.pdf][alali2008s]])
  - TODO
  - Maybe a bit old?
  - Useful to know what terms to use
  - According to [[cortes2014automatically]] the most used terms are fix, add,
    test, bug, patch and the most used combinations are file-fix, fix-use,
    add-bug, remove-test, and file-update.
- /On the Nature of Commits/
  ([[https://sci-hub.tw/10.1109/ASEW.2008.4686322][hattori2008nature]])
  + TODO
- /What do large commits tell us? A taxonomical study of large commits/
  ([[http://maveric0.uwaterloo.ca/~migod/846/papers/msr08-hindle.pdf][hindle2008large]])
  + TODO
- /Cognitive Processes in Program Comprehension/
  ([[https://ac.els-cdn.com/016412128790032X/1-s2.0-016412128790032X-main.pdf?_tid=aff39f10-109e-11e8-8c6f-00000aacb360&acdnat=1518513618_e744f6cb72ebf42954fbb25e1eb42220][letovsky1987cognitive]])
  + Foundational paper
- /On the Naturalness of Software/
  ([[http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6227135][hindle2012naturalness]])
  + Code is repetitive and predictable

**** Code Evolution
- /Erlang Code Evolution Control/
  ([[https://arxiv.org/pdf/1709.05291.pdf][arXiv:1709.05291]])
  + TODO

**** Not Relevant
***** Knowledge
- /Poster: Construct Bug Knowledge Graph for Bug Resolution/
  ([[http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7965299][wang2017construct]])
- /Towards the Visualization of Usage and Decision Knowledge in Continuous Software Engineering/
  ([[https://wwwbruegge.in.tum.de/lehrstuhl_1/research/paper/johanssen2017visualization.pdf][johanssen2017towards]])
  + Pretty figures
  + Design of a tool to visualize various kinds of knowledge
- /Method Execution Reports: Generating Text and Visualization to Describe Program Behavior/
  ([[http://bergel.eu/MyPapers/Beck17a-MethodExecutionReports.pdf][beck2017method]])
***** Others
- /A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes/
  ([[https://arxiv.org/pdf/1704.04856.pdf][loyola2017neural]])
  + Multiple good citation to papers on NL and SE
- /Automatically Capturing Source Code Context of NL-Queries for Software Maintenance and Reuse/
  ([[http://servo.cs.wlu.edu/pubs/bitstream/handle/id/199/Hill09.pdf?sequence=4][hill2009automatically]])
- /How to effectively use topic models for software engineering tasks? an approach based on genetic algorithms/
  ([[https://dl.acm.org/citation.cfm?id=2486788.2486857][panichella2013effectively]])
  + Enhancement that doesn't really interest us
  + "in the context of three different SE tasks: (1) traceability link recovery,
    (2) feature location, and (3) software artifact labeling."
- /Software traceability with topic modeling/
  ([[https://dl.acm.org/citation.cfm?doid=1806799.1806817][asuncion2010software]])
  + "navigate the software architecture and view semantic topics associated with
    relevant artifacts and architectural components"

** Contribution


* Development


* Global Goals
** TODO Report <2018-06-08 Fri 12:00>
** TODO Defense <2018-06-25 Mon>
- TODO Defense Rehearsal @ ENS <2018-06-22 Fri>


* Journal
** Preliminary Bibliographical Work <2017-09-18 Mon>--<2018-02-07 Wed>
*** Things Done
- Meeting with Benoit <2017-09-22 Fri>
  + [[https://github.com/STAMP-project/dspot/issues/187][1]], [[https://github.com/STAMP-project/dspot/issues/129][2]], [[https://github.com/STAMP-project/dspot/issues/54][3]] issues for possible work to do
  + 1 possible work: explain if a mutant isn't killed because of oracle or input
  + focus on mutation (e.g. mutation score)
  + work will be on [[https://github.com/STAMP-project/dspot][Dspot]] and [[https://github.com/STAMP-project/pitest-descartes][PIT]].
- Read [[http://massol.myxwiki.org/xwiki/bin/view/Blog/MutationTestingDescartes][blog on PIT and Descartes]]
  + Sum up PIT/Descartes
  + List of wanted features
- Meeting with Benoit <2017-11-23 Thu>
  + The purpose of DSpot has shifted right?
    - interesting to talk about the history in bibliography? No, there is a new
      paper
  + Enough space to talk about related work? present a few papers in details and
    cite others
  + Current organisation of bibliography
    - General techniques
      + Definitions
      + Mutants
      + etc
    - Useful tools
      + DSpot
  + do extensive evaluation (comparison from scratch vs amplification)
  + find literals to help tests
  + add mutation operator for specific data structures
  + stack mutations
  + add explanations
  + 3 big open problems
- Meeting with Benoit <2017-12-22 Fri>
  + reduce only the generated tests
  + big question: minimal generated tests
    - pre or post treatement
    - order of presenting PRs
    - this is the big question
    - we don't want to touch the original suite
    - we want the programmer to understand the new tests
  + add an example of junit test
  + talk about the trend of genetic improvement
  + don't necesseraly cite /Automatic software diversity in the light of test
    suites/ and /Tailored source code transformations to synthesize
    computationally diverse program variants/
- Talk rehearsal <2018-01-28 Mon 08:30>, notes by Vladislav
  - More illustrations (workflow graph?)
  + Check the test case example (too complicated for not much, not really java)
  + Year and conference acronym in footcite
  + Careful with lambdas for TDR (check with supervisor)
  + More details on commits/pull requests and emphasize the importance of
    developers reviewing generated tests
  + Slide 10 -> ugly (different spacings)
  + Stacking operators: explanation too sparse
  + 4th point in conclusion slide too vague. Not just the goal but also the mean
    to achieve it
- [[https://blog.acolyer.org/2018/01/23/why-is-random-testing-effective-for-partition-tolerance-bugs/]]

*** Blocking Points

*** Planned Work
- [X] Read papers
- [X] Meeting with Benoit <2017-09-22 Fri 15:00-15:30>
- [X] Meeting with Benoit <2017-11-23 Thu 15:00-16:00>
- [X] Send link to repo
- [X] Ask Maud about plane tickets refund
- [X] Meeting with Benoit <2017-12-22 Fri 10:30-11:30>


** Week 1 & 2 <2018-02-07 Wed>--<2018-02-18 Sun>
*** Things Done
- Wrote the little example of use of Spoon (I simply added it in [[https://github.com/SpoonLabs/spoon-examples][spoon-examples]])
#+NAME: RemoveIf
#+BEGIN_SRC java
package fr.inria.gforge.spoon.transformation;

import spoon.processing.AbstractProcessor;
import spoon.reflect.code.*;

/**
 * Removes if when there is no else and if the body consists only of a return
 *
 * @author Simon Bihel
 */
public class RemoveIfReturn extends AbstractProcessor<CtIf> {

    @Override
    public void process(CtIf element) {
        CtStatement elseStmt = element.getElseStatement();
        if (elseStmt == null) { return; } // should not be an else

        CtStatement thenStmt = element.getThenStatement();
        if (thenStmt instanceof CtReturn) { // simple case with directly a then statement
            element.replace(thenStmt);
            return;
        }
        if (thenStmt instanceof CtBlock) { // case with a block which first statement is a return
            CtStatement firstStmt = ((CtBlock) thenStmt).getStatement(0);
            if (firstStmt instanceof CtReturn) {
                element.replace(thenStmt);
            }
        }
    }
}
#+END_SRC
#+Name: RemoveIfTest
#+BEGIN_SRC java
#+END_SRC
- [[https://clang-analyzer.llvm.org/][Clang static analyzer]] for windows
  + Clang is painful to install on Windows... It requires llvm and Microsoft
    Visual Studio. And there is no other choice than building from source. And
    it requires Perl to run.
  + Should probably use [[http://cppcheck.sourceforge.net/][CPPcheck]]
  + Cppcheck has a GUI and an installer for Windows. 👍
  + example of bugs [[http://courses.cs.vt.edu/~cs1206/Fall00/bugs_CAS.html]]
- To what extent are documenting source code changes useful for us?
  + Only few changes made by DSpot
  + The source of the change is a tool, not a human
  + Still useful to see how they formulate features in natural language
  + DSpot doesn't add new features, we want the purpose of enhanced tests.
  + Don't really care about Pyramid method because it compares with human
    written messages
- GitHub's [[https://help.github.com/articles/creating-a-pull-request-template-for-your-repository/][PR templates]] are just plain text templates.
- Went through papers that cited ChangeScribe. Went partly through citations by
  ChangeScribe.
- Spent a lot of time on generating natural language from source code

*** Blocking Points
- Software Maintenance seems to be an important keyword/field for the
  documentation of code
- Is it useful to explore approaches for augmenting the context provided by
  differencing tools?

*** Planned Work
- [ ] Read papers
- [ ] should I register for ICST? and ICSE?
- [X] Sign papers grant
- [X] Is there a Slack or something?
- [-] Get familiar with Spoon
  + [ ] Read paper
  + [-] Little project, remove `if`s when there is no `else` and the body is
    just a `return`.
    - [X] Write the program
    - [ ] Write tests
- [ ] Get familiar with Dspot
- [ ] See /boiler-plates/ for NLP way of building sentences.
  + [ ] Search for papers and read them
- [X] Sign contract with KTH Relocation <2018-02-13 Tue 14:00>--<2018-02-13 Tue 15:30>
- [X] Categorize papers of preliminaries
- [-] Lookup what static analysis is possible with +clang+ Cppcheck [33%]
  + [X] find tools
  + it is for mechatronics students who write small programs for arduinos
  + show them what tests are and what's possible to discover bugs
  + [ ] Think of what they could be taught
  + [-] Test Cppcheck on a windows machine
    - [X] Install windows on the small computer
    - [ ] Test the code provided in the course


* Conclusion
